{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import gzip\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./HAAFOR')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "vocab_list = pd.read_csv('./data/merged_20000.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = \"./data/merged_20000.model\"\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict): \n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=Config({'n_layers':1,'n_head':1,'d_model':256,'n_token':0,'hidden_dim':4*256,'padding_idx':1,'seq_len':1000,'batch_size':32,'dropout':0.1,'max_len':5000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분석하기 전에 torchtext를 활용하기\n",
    "# torchtext에 있는 사전 훈련된 임베딩 벡터 활용하기\n",
    "# torchtext iterator는 drop_last를 못한다.\n",
    "import torchtext\n",
    "TEXT=torchtext.data.Field(sequential=True,use_vocab=True,init_token='<s>',eos_token='</s>',tokenize=sp.encode_as_pieces,fix_length=config.seq_len,batch_first=False,lower=True,pad_token='<pad>',unk_token='<unk>') \n",
    "ISNEXT=torchtext.data.Field(sequential=False,use_vocab=False,batch_first=False,is_target=True) \n",
    "Train_data=torchtext.data.TabularDataset('./data/train_data_10000_swap.csv',format='csv',fields=[('A',TEXT),('B',TEXT),('NEXT',ISNEXT)],skip_header=True) # 이 때 train data는 sentence형태 이여야함.(tokenized가 되지 않은 상태)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18201\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(Train_data)\n",
    "print(len(TEXT.vocab.stoi)) # 18201 <- 내가 적당하게 seq(1000)를 잘라냈기 때문에 발생한다.\n",
    "config['n_token']=len(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loader\n",
    "train_loader=torchtext.data.Iterator(Train_data,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model - attention model을 활용한다.\n",
    "import math\n",
    "# positional encoding\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.config=config\n",
    "        self.dropout = nn.Dropout(p=self.config.dropout)\n",
    "        self.pe = torch.zeros(config.max_len, config.d_model).to(device)\n",
    "        position = torch.arange(0, config.max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, config.d_model, 2).float() * (-math.log(10000.0) / config.d_model))\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = self.pe.unsqueeze(0).transpose(0,1) # max len, 1, d_model\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x shape : seq len, batch size, d model\n",
    "        '''\n",
    "        self.pe=self.pe.to(x.device)\n",
    "        x = x + self.pe[:x.size(0),:,:] # 후 항 shape : seq len, 1, d model\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.config=config\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "        self.mask = None\n",
    "        self.pos_encoder = PositionalEncoding(self.config)\n",
    "        encoder_layers = TransformerEncoderLayer(self.config.d_model,self.config.n_head, self.config.hidden_dim, self.config.dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, self.config.n_layers)\n",
    "        decoder_layers = TransformerDecoderLayer(self.config.d_model,self.config.n_head, self.config.hidden_dim, self.config.dropout)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, self.config.n_layers)\n",
    "        self.embedding = nn.Embedding(self.config.n_token, self.config.d_model)\n",
    "        self.fc=nn.Sequential(nn.Linear(self.config.d_model*self.config.seq_len,self.config.d_model),nn.ReLU(),nn.Linear(self.config.d_model,1),nn.Sigmoid())\n",
    "    def gen_padding_mask(self, input):\n",
    "        '''\n",
    "        input shape : seq len, batch size\n",
    "        embedding(input) : seq len, batch size, d_model\n",
    "        mask shape : seq len, batch size <- seq len에서 padding idx인 녀석은 1, 나머지는 0\n",
    "        근데 TransformerEncoder에 넣어주기 위해선 batch size, seq len으로 바꿔줘야 한다.\n",
    "        subsquent mask와는 다르다. -> TransformerEncoder에선 src_key_padding_mask의 input으로 들어감\n",
    "        '''\n",
    "        mask=input.eq(self.config.padding_idx).T \n",
    "        return mask\n",
    "    \n",
    "    def forward(self, src,tgt):\n",
    "        device=src.device\n",
    "        src_key_padding_mask = self.gen_padding_mask(src)\n",
    "        tgt_key_padding_mask = self.gen_padding_mask(tgt)\n",
    "        self.src_key_padding_mask = src_key_padding_mask.to(device)\n",
    "        self.tgt_key_padding_mask = tgt_key_padding_mask.to(device)\n",
    "        src_out = self.embedding(src) * math.sqrt(self.config.d_model)\n",
    "        src_out = self.pos_encoder(src_out)\n",
    "        src_out = self.transformer_encoder(src_out)\n",
    "        tgt_out = self.embedding(tgt) * math.sqrt(self.config.d_model)\n",
    "        tgt_out = self.pos_encoder(tgt_out)\n",
    "        out = self.transformer_decoder(tgt_out,src_out,tgt_key_padding_mask=self.tgt_key_padding_mask,\n",
    "                                         memory_key_padding_mask=self.src_key_padding_mask)\n",
    "        out = out.transpose(0,1) # batch size, seq_len, d_model\n",
    "        out = out.reshape(-1,self.config.seq_len*self.config.d_model)\n",
    "        output = self.fc(out) #  batch size, 1\n",
    "        return output.squeeze(-1) # batch size <- 그냥 squeeze()로 하면 1인 녀석이 다 지워짐..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train():\n",
    "    model.train() # 학습 모드를 시작합니다.\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    n=0\n",
    "    for _,ok in enumerate(train_loader):\n",
    "        src,tgt,is_next=ok.A,ok.B,ok.NEXT\n",
    "        src=src.to(device)\n",
    "        tgt=tgt.to(device)\n",
    "        is_next=is_next.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src,tgt)\n",
    "        try :\n",
    "            loss = criterion(output, is_next)\n",
    "        except:\n",
    "            print(output)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # clip을 해준다.\n",
    "        optimizer.step()\n",
    "        n+=1\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if _ % 100 == 0 and _ > 0:\n",
    "            print('-' * 89)\n",
    "            print('| epoch %d | batches %d | loss %.2f | processed_time %.1f'%(\n",
    "                    epoch, _, total_loss/n, time.time()-start_time))      \n",
    "            print('-' * 89)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 해보즈아\n",
    "import time\n",
    "device = 'cuda:0'\n",
    "model = TransformerModel(config).to(device)\n",
    "# model = torch.nn.DataParallel(model).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "epochs = 10000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train() # 학습 모드를 시작합니다.\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    n=0\n",
    "    for _,ok in enumerate(train_loader):\n",
    "        src,tgt,is_next=ok.A,ok.B,ok.NEXT\n",
    "        src=src.to(device)\n",
    "        tgt=tgt.to(device)\n",
    "        is_next=is_next.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src,tgt)\n",
    "        loss = criterion(output, is_next)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # clip을 해준다.\n",
    "        optimizer.step()\n",
    "        n+=1\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if epoch%100==0 and epoch>0 and _ % 100 == 0 and _ > 0:\n",
    "            print('-' * 89)\n",
    "            print('| epoch %d | batches %d | loss %.2f | processed_time %.1f'%(\n",
    "                    epoch, _, total_loss/n, time.time()-start_time))      \n",
    "            print('-' * 89)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[haafor]",
   "language": "python",
   "name": "haafor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
